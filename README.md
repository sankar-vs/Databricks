## Databricks
### CPU Logs
* From the given data store it on onpremises DBFS
* Preprocess the data in Data Bricks using Python Notebook
* The Used Cases are:
    * Finding users with lowest number of average hours
    * Finding users with highest number of average hours
    * Finding users with highest numbers of times late comings
    * Finding users with highest numbers of idle hours
    * Store the cleaning data on onpremises DB
    * Store results on BLOB Storage
### Sentiment Analytics Using Python
* Create a Twitter Developer Account
* Have both the Consumer and Access Token
* Make a connection with the twiiter using the credentials and sockets
* Search accoeding to a unique hashtag
* Display the message in another file while connecting to that socket according to the Hashtag searched
* Store the messages from a particular search, clean the tweet, analyse the tweet using TweetBlob and segregate them accoding to their sentiments (Positive, Negative and Neutral)
### Kafka
* Install Kafka 
* Change the Zookeeper and Server properties path by creating a seperate folder for zookeeper and broker
* Start the zookeeper server, Kafka server
* Create a new Topic
* Start Consumer Console and Producer Console
* Try passing message in Producer Console and check whether the same is refected in Consumer Console
* Instal Kafka-Python using pip instal kafka-python
* Create a Consumer.py and Producer.py
* Try sending message streams from producer to consumer.py
